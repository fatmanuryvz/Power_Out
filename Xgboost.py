import simpy
import random
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt



# ğŸ”§ 1. Mevsime baÄŸlÄ± sÃ¼re Ã§arpanlarÄ± (YazÄ±n daha uzun olabilir)
season_multipliers = {
    'yaz': 1.3,
    'kÄ±ÅŸ': 1.2,
    'bahar': 1.0,
    'sonbahar': 1.1
}

# ğŸ˜ï¸ 2. Ä°zmir ilÃ§elerinin altyapÄ± Ã¶zellikleri
districts_template = {
    'Konak':     {'infrastructure_score': 0.8, 'has_critical_infra': True,  'has_backup_power': True},
    'Bornova':   {'infrastructure_score': 0.7, 'has_critical_infra': True,  'has_backup_power': False},
    'KarÅŸÄ±yaka': {'infrastructure_score': 0.6, 'has_critical_infra': False, 'has_backup_power': False},
    'AliaÄŸa':    {'infrastructure_score': 0.9, 'has_critical_infra': True,  'has_backup_power': True},
    'Tire':      {'infrastructure_score': 0.4, 'has_critical_infra': False, 'has_backup_power': False},
    'Ã‡eÅŸme':     {'infrastructure_score': 0.5, 'has_critical_infra': False, 'has_backup_power': True},
}

# ğŸ”¢ 3. Ä°lÃ§eye Ã¶ncelik ve mÃ¼dahale sÃ¼resi hesaplayan yardÄ±mcÄ± fonksiyonlar
def compute_priority(d):
    priority = d['infrastructure_score']
    if d['has_critical_infra']:
        priority += 0.2
    return min(priority, 1.0)

def compute_recovery_time(d, season):
    base_time = 60
    if d['infrastructure_score'] < 0.5:
        base_time += 30
    if d['has_backup_power']:
        base_time *= 0.6
    base_time *= season_multipliers[season]
    return int(base_time)

# ğŸ” 4. Tek bir kesinti senaryosu oluÅŸturur
def run_single_simulation(season):
    districts = {k: v.copy() for k, v in districts_template.items()}
    for d in districts.values():
        d['priority'] = compute_priority(d)
        d['recovery_time'] = compute_recovery_time(d, season)
    results = []

    def power_outage(env, name, recovery_time, priority, grid):
        start = env.now
        with grid.request(priority=1.0 - priority) as req:
            yield req
            yield env.timeout(recovery_time)
            end = env.now
            results.append({
                'ilÃ§e': name,
                'altyapÄ±_skoru': districts[name]['infrastructure_score'],
                'kritik_tesis': int(districts[name]['has_critical_infra']),
                'yedek_gÃ¼Ã§': int(districts[name]['has_backup_power']),
                'mevsim': season,
                'sÃ¼re': end - start
            })

    def delayed_outage(env, delay, name, recovery_time, priority, grid):
        yield env.timeout(delay)
        yield env.process(power_outage(env, name, recovery_time, priority, grid))

    env = simpy.Environment()
    grid = simpy.PriorityResource(env, capacity=2)
    for name, info in districts.items():
        delay = random.randint(0, 20)
        env.process(delayed_outage(env, delay, name, info['recovery_time'], info['priority'], grid))
    env.run()
    return results

# ğŸ”„ 5. 100 farklÄ± simÃ¼lasyon Ã§alÄ±ÅŸtÄ±rarak veri Ã¼ret (veri seti oluÅŸturuluyor)
print("ğŸ”„ 100 farklÄ± senaryo ile veri oluÅŸturuluyor...")
all_data = []
for i in range(100):
    season = random.choice(list(season_multipliers.keys()))
    sim_data = run_single_simulation(season)
    all_data.extend(sim_data)

df = pd.DataFrame(all_data)

# ğŸ’¾ Dosyaya yaz ve varsa eski verilerle birleÅŸtir
try:
    eski = pd.read_csv("genis_egitim_verisi.csv")
    birlesik = pd.concat([eski, df]).drop_duplicates()
except FileNotFoundError:
    birlesik = df

birlesik.to_csv("genis_egitim_verisi.csv", index=False)
print("âœ… Veri seti 'genis_egitim_verisi.csv' olarak kaydedildi.")

# ğŸ§  6. XGBoost ile model eÄŸitimi
print("ğŸ¤– XGBoost modeli eÄŸitiliyor...")

X = df.drop(columns=["ilÃ§e", "sÃ¼re"])
y = df["sÃ¼re"]

# ğŸ§  Mevsimi one-hot encode (model daha iyi Ã¶ÄŸrensin diye)
encoder = OneHotEncoder(sparse_output=False)
season_encoded = encoder.fit_transform(X[["mevsim"]])
season_df = pd.DataFrame(season_encoded, columns=encoder.get_feature_names_out(["mevsim"]))
X = pd.concat([X.drop(columns=["mevsim"]).reset_index(drop=True), season_df.reset_index(drop=True)], axis=1)

# ğŸ”€ Veri setini eÄŸitim/test olarak ayÄ±r
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ğŸ“ˆ Modeli eÄŸit
model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)



import matplotlib.pyplot as plt
import pandas as pd

# Ã–zellik Ã¶nem skorlarÄ±nÄ± al
importances = model.feature_importances_
feature_names = X.columns

# DataFrame oluÅŸtur
importance_df = pd.DataFrame({
    "Ã–zellik": feature_names,
    "Ã–nem": importances
}).sort_values(by="Ã–nem", ascending=True)

# Grafik Ã§izimi
plt.figure(figsize=(10, 6))
plt.barh(importance_df["Ã–zellik"], importance_df["Ã–nem"], color="seagreen")
plt.title("XGBoost Modelinde Ã–zellik Ã–nem Dereceleri")
plt.xlabel("Ã–neme Skoru")
plt.grid(True)
plt.show()


# ğŸ“Š 7. BaÅŸarÄ± Ã¶lÃ§Ã¼tleri
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"ğŸ“Š Ortalama Hata (MAE): {mae:.2f} dakika")
print(f"ğŸ“ˆ RÂ² Skoru : {r2:.2f} ")

# ğŸ“‰ 8. Tahmin ve gerÃ§ek deÄŸerleri grafikle karÅŸÄ±laÅŸtÄ±r
print("ğŸ“Š GerÃ§ek ve tahmin edilen sÃ¼reler gÃ¶rselleÅŸtiriliyor...")
compare_df = pd.DataFrame({"GerÃ§ek SÃ¼re": y_test.values, "Tahmin SÃ¼re": y_pred})
compare_df.plot(kind='scatter', x="GerÃ§ek SÃ¼re", y="Tahmin SÃ¼re", alpha=0.6)
plt.title("GerÃ§ek vs Tahmin Edilen SÃ¼re")
plt.xlabel("GerÃ§ek SÃ¼re (dk)")
plt.ylabel("Tahmin Edilen SÃ¼re (dk)")
plt.grid(True)
plt.tight_layout()
plt.show()

from joblib import dump

# EÄŸittiÄŸin modeli ve encoder'Ä± kaydet
dump(model, "xgb_model.joblib")
dump(encoder, "onehot_encoder.joblib")

print("âœ… Model ve encoder dosya olarak kaydedildi.")

